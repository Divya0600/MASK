{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj0qcWLk9xBA",
        "outputId": "4dd99052-9aa6-43e5-c4f6-81ae039537c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting presidio-analyzer\n",
            "  Downloading presidio_analyzer-2.2.357-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting presidio-anonymizer\n",
            "  Downloading presidio_anonymizer-2.2.357-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio-analyzer)\n",
            "  Downloading phonenumbers-8.13.53-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from presidio-analyzer) (2024.11.6)\n",
            "Collecting tldextract (from presidio-analyzer)\n",
            "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core (from presidio-anonymizer)\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting pycryptodome>=3.10.1 (from presidio-anonymizer)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core->presidio-anonymizer) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio-analyzer)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->presidio-analyzer) (3.16.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Downloading presidio_analyzer-2.2.357-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading presidio_anonymizer-2.2.357-py3-none-any.whl (31 kB)\n",
            "Downloading phonenumbers-8.13.53-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: phonenumbers, pycryptodome, requests-file, azure-core, tldextract, presidio-anonymizer, presidio-analyzer\n",
            "Successfully installed azure-core-1.32.0 phonenumbers-8.13.53 presidio-analyzer-2.2.357 presidio-anonymizer-2.2.357 pycryptodome-3.21.0 requests-file-2.1.0 tldextract-5.1.3\n"
          ]
        }
      ],
      "source": [
        "%pip install presidio-analyzer presidio-anonymizer spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "import os\n",
        "import requests\n",
        "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
        "\n",
        "# Disable SSL verification (for your use case)\n",
        "os.environ['CURL_CA_BUNDLE'] = ''\n",
        "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
        "\n",
        "# Load the local SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create Presidio Analyzer and Anonymizer Engines\n",
        "from presidio_analyzer.nlp_engine import SpacyNlpEngine\n",
        "\n",
        "# Pass the model name, not the actual model object\n",
        "nlp_engine = SpacyNlpEngine(models=[{\"lang_code\": \"en\", \"model_name\": \"en_core_web_sm\"}])  # Use the model name here\n",
        "analyzer = AnalyzerEngine(nlp_engine=nlp_engine)\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "# Function to mask PII entities using Presidio\n",
        "def mask_pii_with_presidio(text):\n",
        "    # Analyze the text to find PII\n",
        "    results = analyzer.analyze(text=text, language=\"en\")\n",
        "\n",
        "    # Print detected entities and their labels\n",
        "    for result in results:\n",
        "        print(f\"Entity: {result.entity_type}, Text: {text[result.start:result.end]}\")\n",
        "\n",
        "    # Anonymize (mask) the detected PII entities\n",
        "    anonymized_text = anonymizer.anonymize(text, results)\n",
        "\n",
        "    return anonymized_text\n",
        "\n",
        "# Sample input text with PII\n",
        "input_text = \"\"\"\n",
        "John Doe lives at 123 Elm Street, Springfield. His company, TechCorp, pays him a salary of $50,000.\n",
        "He was born on 12th July 1990 and works from 9 AM to 5 PM.\n",
        "\"\"\"\n",
        "\n",
        "# Mask the PII from the input text\n",
        "masked_output = mask_pii_with_presidio(input_text)\n",
        "\n",
        "print(\"\\nMasked Output:\\n\", masked_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSELP-qz96uN",
        "outputId": "51d724d4-8f20-4f44-cf91-53761ff622ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:model_to_presidio_entity_mapping is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:low_score_entity_names is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: PERSON, Text: John Doe\n",
            "Entity: LOCATION, Text: Springfield\n",
            "Entity: DATE_TIME, Text: 12th July 1990\n",
            "Entity: DATE_TIME, Text: 9 AM to 5 PM\n",
            "\n",
            "Masked Output:\n",
            " text: \n",
            "<PERSON> lives at 123 Elm Street, <LOCATION>. His company, TechCorp, pays him a salary of $50,000.\n",
            "He was born on <DATE_TIME> and works from <DATE_TIME>.\n",
            "\n",
            "items:\n",
            "[\n",
            "    {'start': 142, 'end': 153, 'entity_type': 'DATE_TIME', 'text': '<DATE_TIME>', 'operator': 'replace'},\n",
            "    {'start': 115, 'end': 126, 'entity_type': 'DATE_TIME', 'text': '<DATE_TIME>', 'operator': 'replace'},\n",
            "    {'start': 35, 'end': 45, 'entity_type': 'LOCATION', 'text': '<LOCATION>', 'operator': 'replace'},\n",
            "    {'start': 1, 'end': 9, 'entity_type': 'PERSON', 'text': '<PERSON>', 'operator': 'replace'}\n",
            "]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from presidio_analyzer import AnalyzerEngine, RecognizerResult, EntityRecognizer\n",
        "from presidio_analyzer.nlp_engine import SpacyNlpEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_analyzer.recognizer_registry import RecognizerRegistry\n",
        "\n",
        "# Load SpaCy model\n",
        "spacy_model_path = \"en_core_web_sm\"\n",
        "try:\n",
        "    nlp = spacy.load(spacy_model_path)\n",
        "    print(\"SpaCy model loaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading SpaCy model: {e}\")\n",
        "\n",
        "# Initialize SpaCy NLP Engine\n",
        "nlp_engine = SpacyNlpEngine(models=[{\"lang_code\": \"en\", \"model_name\": spacy_model_path}])\n",
        "\n",
        "# Custom recognizer for allowlist\n",
        "class AllowlistRecognizer(EntityRecognizer):\n",
        "    def __init__(self, allowlist):\n",
        "        super().__init__()\n",
        "        self.allowlist = allowlist\n",
        "\n",
        "    def load(self):\n",
        "        pass  # No external models to load\n",
        "\n",
        "    def analyze(self, text, entities, nlp_artifacts=None):\n",
        "        results = []\n",
        "        for word in self.allowlist:\n",
        "            start = text.find(word)\n",
        "            if start != -1:\n",
        "                end = start + len(word)\n",
        "                results.append(\n",
        "                    RecognizerResult(entity_type=\"ALLOWLIST\", start=start, end=end, score=1.0)\n",
        "                )\n",
        "        return results\n",
        "\n",
        "# Custom recognizer for denylist\n",
        "class DenylistRecognizer(EntityRecognizer):\n",
        "    def __init__(self, denylist):\n",
        "        super().__init__()\n",
        "        self.denylist = denylist\n",
        "\n",
        "    def load(self):\n",
        "        pass  # No external models to load\n",
        "\n",
        "    def analyze(self, text, entities, nlp_artifacts=None):\n",
        "        results = []\n",
        "        for word in self.denylist:\n",
        "            start = text.find(word)\n",
        "            if start != -1:\n",
        "                end = start + len(word)\n",
        "                results.append(\n",
        "                    RecognizerResult(entity_type=\"DENYLIST\", start=start, end=end, score=1.0)\n",
        "                )\n",
        "        return results\n",
        "\n",
        "# Create allowlist and denylist\n",
        "allowlist = {\"TechCorp\", \"Springfield\"}  # Words to ignore\n",
        "denylist = {\"John\", \"Doe\", \"Elm Street\"}  # Words to always mask\n",
        "\n",
        "# Register custom recognizers\n",
        "registry = RecognizerRegistry()\n",
        "registry.add_recognizer(AllowlistRecognizer(allowlist))\n",
        "registry.add_recognizer(DenylistRecognizer(denylist))\n",
        "\n",
        "# Initialize AnalyzerEngine and AnonymizerEngine\n",
        "analyzer = AnalyzerEngine(registry=registry, nlp_engine=nlp_engine)\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "# Function to mask PII with allowlist and denylist handling\n",
        "def mask_pii_with_lists(text):\n",
        "    # Analyze the text\n",
        "    results = analyzer.analyze(\n",
        "        text=text,\n",
        "        language=\"en\",\n",
        "        score_threshold=0.5,  # Threshold for PII detection\n",
        "    )\n",
        "\n",
        "    # Filter results based on allowlist/denylist\n",
        "    filtered_results = []\n",
        "    for result in results:\n",
        "        if result.entity_type == \"ALLOWLIST\":\n",
        "            print(f\"Skipping allowlist word: {text[result.start:result.end]}\")\n",
        "            continue\n",
        "        if result.entity_type == \"DENYLIST\":\n",
        "            print(f\"Forcing denylist word: {text[result.start:result.end]}\")\n",
        "        filtered_results.append(result)\n",
        "\n",
        "    # Anonymize (mask) the filtered entities\n",
        "    anonymized_text = anonymizer.anonymize(\n",
        "        text=text,\n",
        "        analyzer_results=filtered_results,\n",
        "        operators={\"DEFAULT\": {\"type\": \"replace\", \"new_value\": \"<MASK>\"}}\n",
        "    )\n",
        "\n",
        "    return anonymized_text.text\n",
        "\n",
        "# Sample text\n",
        "input_text = \"\"\"\n",
        "John Doe lives at 123 Elm Street, Springfield. His company, TechCorp, pays him a salary of $50,000.\n",
        "He was born on 12th July 1990 and works from 9 AM to 5 PM.\n",
        "\"\"\"\n",
        "\n",
        "# Run the masking function\n",
        "masked_output = mask_pii_with_lists(input_text)\n",
        "print(\"\\nMasked Output:\\n\", masked_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "dGGl9ZhS-GRI",
        "outputId": "5009c02e-9f1d-4bf2-deb4-aab43a62b906"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:model_to_presidio_entity_mapping is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:low_score_entity_names is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy model loaded successfully!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "EntityRecognizer.__init__() missing 1 required positional argument: 'supported_entities'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e072ac071f5d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Register custom recognizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mregistry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecognizerRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_recognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAllowlistRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallowlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_recognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDenylistRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenylist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-e072ac071f5d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, allowlist)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAllowlistRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEntityRecognizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallowlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallowlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: EntityRecognizer.__init__() missing 1 required positional argument: 'supported_entities'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "\n",
        "# Load SpaCy model for NLP\n",
        "spacy_model_path = \"en_core_web_sm\"\n",
        "nlp = spacy.load(spacy_model_path)\n",
        "\n",
        "# Initialize SpaCy NLP Engine\n",
        "nlp_engine = SpacyNlpEngine(models=[{\"lang_code\": \"en\", \"model_name\": spacy_model_path}])\n",
        "\n",
        "# Initialize Analyzer Engine\n",
        "analyzer = AnalyzerEngine(nlp_engine=nlp_engine)\n",
        "\n",
        "# Initialize Anonymizer Engine\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "# Define Allowlist and Denylist\n",
        "allowlist = [\"TechCorp\", \"Springfield\"]\n",
        "denylist = [\"John\", \"Doe\", \"Elm Street\"]\n",
        "\n",
        "# Mask PII Function\n",
        "def mask_pii(text):\n",
        "    # Analyze the text for PII entities\n",
        "    results = analyzer.analyze(text=text, language=\"en\", score_threshold=0.5)\n",
        "\n",
        "    # Filter out allowlisted entities\n",
        "    filtered_results = [\n",
        "        result for result in results if result.entity_type not in [\"ALLOWLIST\"] and result.entity_type != \"DENYLIST\"\n",
        "    ]\n",
        "\n",
        "    # Anonymize (mask) the text based on filtered results\n",
        "    anonymized_text = anonymizer.anonymize(text=text, analyzer_results=filtered_results)\n",
        "\n",
        "    return anonymized_text.text\n",
        "\n",
        "# Test Input\n",
        "input_text = \"\"\"\n",
        "John Doe lives at 123 Elm Street, Springfield. His company, TechCorp, pays him a salary of $50,000.\n",
        "He was born on 12th July 1990 and works from 9 AM to 5 PM.\n",
        "\"\"\"\n",
        "\n",
        "# Run the function\n",
        "masked_text = mask_pii(input_text)\n",
        "print(\"\\nMasked Output:\\n\", masked_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnj3TkVY_J2U",
        "outputId": "1e6c832c-9414-4849-fb09-eacec1241814"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:model_to_presidio_entity_mapping is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:low_score_entity_names is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Entity FAC is not mapped to a Presidio entity, but keeping anyway. Add to `NerModelConfiguration.labels_to_ignore` to remove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Masked Output:\n",
            " \n",
            "<PERSON> lives at 123 Elm Street, <LOCATION>. His company, TechCorp, pays him a salary of $50,000.\n",
            "He was born on <DATE_TIME> and works from <DATE_TIME>.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_analyzer.nlp_engine import SpacyNlpEngine\n",
        "import spacy\n",
        "from presidio_analyzer import RecognizerRegistry\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.getLogger(\"presidio-analyzer\").setLevel(logging.ERROR)\n",
        "\n",
        "# Load SpaCy model for NLP\n",
        "spacy_model_path = \"en_core_web_sm\"\n",
        "nlp = spacy.load(spacy_model_path)\n",
        "\n",
        "# Configure NLP Engine with ignored labels\n",
        "nlp_engine = SpacyNlpEngine(\n",
        "    models=[{\n",
        "        \"lang_code\": \"en\",\n",
        "        \"model_name\": spacy_model_path,\n",
        "        \"labels_to_ignore\": [\"FAC\"]  # Ignore facility labels\n",
        "    }]\n",
        ")\n",
        "\n",
        "# Initialize Analyzer Engine with registry\n",
        "registry = RecognizerRegistry()\n",
        "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, registry=registry)\n",
        "\n",
        "# Initialize Anonymizer Engine\n",
        "anonymizer = AnonymizerEngine()\n",
        "\n",
        "def mask_pii(text, allowlist=None, denylist=None):\n",
        "    if allowlist is None:\n",
        "        allowlist = []\n",
        "    if denylist is None:\n",
        "        denylist = []\n",
        "\n",
        "    try:\n",
        "        # Analyze the text for PII entities\n",
        "        results = analyzer.analyze(\n",
        "            text=text,\n",
        "            language=\"en\",\n",
        "            score_threshold=0.5,\n",
        "            entities=None,  # Detect all supported entities\n",
        "            return_decision_process=True  # Include analysis explanation\n",
        "        )\n",
        "\n",
        "        # Filter out allowlisted entities\n",
        "        filtered_results = [\n",
        "            result for result in results\n",
        "            if result.entity_type not in allowlist and result.entity_type not in denylist\n",
        "        ]\n",
        "\n",
        "        # Anonymize the text\n",
        "        anonymized_text = anonymizer.anonymize(text=text, analyzer_results=filtered_results)\n",
        "\n",
        "        # Prepare findings for CSV\n",
        "        findings = []\n",
        "        for result in filtered_results:\n",
        "            entity_text = text[result.start:result.end]\n",
        "            finding = {\n",
        "                \"Entity_Type\": result.entity_type,\n",
        "                \"Text\": entity_text,\n",
        "                \"Start\": result.start,\n",
        "                \"End\": result.end,\n",
        "                \"Confidence\": result.score,\n",
        "                \"Source\": \"Presidio Analyzer\"  # Instead of undefined recognizer attribute\n",
        "            }\n",
        "            findings.append(finding)\n",
        "\n",
        "        # Create DataFrame and save to CSV\n",
        "        if findings:  # Only create CSV if there are findings\n",
        "            df = pd.DataFrame(findings)\n",
        "            df.to_csv('findings.csv', index=False)\n",
        "            print(f\"Found {len(findings)} PII entities\")\n",
        "        else:\n",
        "            print(\"No PII entities found\")\n",
        "\n",
        "        return anonymized_text.text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during PII masking: {str(e)}\")\n",
        "        return text  # Return original text if error occurs\n",
        "\n",
        "# Test Input\n",
        "input_text = \"\"\"\n",
        "John Doe lives at 123 Elm Street, Springfield. His company, TechCorp, pays him a salary of $50,000.\n",
        "He was born on 12th July 1990 and works from 9 AM to 5 PM.\n",
        "\"\"\"\n",
        "\n",
        "# Specify entities to ignore (optional)\n",
        "ignore_entities = [\"FAC\"]  # Ignore facility entities\n",
        "\n",
        "# Run the function\n",
        "masked_text = mask_pii(input_text)\n",
        "print(\"\\nMasked Output:\\n\", masked_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EfHsA3sHmEJ",
        "outputId": "61054e0c-5a50-471e-b443-cb7decb39d26"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4 PII entities\n",
            "\n",
            "Masked Output:\n",
            " \n",
            "<PERSON> lives at 123 Elm Street, <LOCATION>. His company, TechCorp, pays him a salary of $50,000.\n",
            "He was born on <DATE_TIME> and works from <DATE_TIME>.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIIbGcT4NV8R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}